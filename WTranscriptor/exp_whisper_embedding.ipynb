{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Embeddding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SIZE = 'openai/whisper-base.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperModel.from_pretrained(MODEL_SIZE)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalize_audio(filename=''):\n",
    "    '''\n",
    "    Read an Audio file as int16 array\n",
    "    Normalize it\n",
    "    '''\n",
    "    wave,info = sf.read(filename,dtype='int16')\n",
    "    wave = wave / np.iinfo(np.int16).max\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(wave):\n",
    "    inputs = feature_extractor(wave, return_tensors=\"pt\") #extract features as pytorch\n",
    "    input_features = inputs.input_features\n",
    "    decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id #dummy decoding ids\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).last_hidden_state #passing input to models\n",
    "    print(list(last_hidden_state.shape))\n",
    "    return last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 512]\n",
      "CPU times: user 4.65 s, sys: 1.35 s, total: 6 s\n",
      "Wall time: 1.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.3620e-03, -5.7831e-01,  1.4868e+00,  ..., -3.2280e+00,\n",
       "          -1.6686e+00,  1.3653e+00],\n",
       "         [-8.6298e+00, -2.0907e+00,  1.8474e+00,  ..., -1.7293e+00,\n",
       "          -7.2221e-01,  1.0072e+01]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/2sec.wav')\n",
    "extract_embeddings(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 512]\n",
      "CPU times: user 5.19 s, sys: 1.24 s, total: 6.43 s\n",
      "Wall time: 1.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2195,  1.4762,  4.0492,  ...,  0.7420,  1.9835,  2.9061],\n",
       "         [-8.8873, -3.2836,  0.5441,  ..., -2.0624,  3.6385, 11.6977]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/preamble_5sec_resample_with_pause.wav')\n",
    "extract_embeddings(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 512]\n",
      "CPU times: user 5.04 s, sys: 1.48 s, total: 6.52 s\n",
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1290,  2.1790, -2.9553,  ...,  2.1216,  2.3728, -6.0154],\n",
       "         [-6.5927, -4.3119,  0.0987,  ...,  1.2869, -0.7027,  7.3346]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/10sec.wav')\n",
    "extract_embeddings(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 512]\n",
      "CPU times: user 4.55 s, sys: 1.42 s, total: 5.96 s\n",
      "Wall time: 1.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.3863,   2.2555,   2.2305,  ...,   0.8704,   4.1336,   0.8985],\n",
       "         [ -4.8217,  -3.9847,   1.2224,  ..., -10.3806,  -4.3587,  13.1559]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/20sec.wav')\n",
    "extract_embeddings(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 512]\n",
      "CPU times: user 5.26 s, sys: 1.35 s, total: 6.6 s\n",
      "Wall time: 1.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1567,  1.2513,  0.6916,  ...,  0.0371, -1.8902, -1.8424],\n",
       "         [-5.6961, -3.2571,  0.1291,  ..., -3.5791, -0.2094,  5.0859]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/40sec.wav')\n",
    "extract_embeddings(wave)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Transcript Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(MODEL_SIZE)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(wave):\n",
    "\n",
    "    '''\n",
    "    Genrate Transcript\n",
    "    '''\n",
    "    inputs = processor(wave, return_tensors=\"pt\")\n",
    "\n",
    "    input_features = inputs.input_features\n",
    "\n",
    "    generated_ids = model.generate(inputs=input_features)\n",
    "\n",
    "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "/home/ali/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 s, sys: 477 ms, total: 6.09 s\n",
      "Wall time: 1.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello, hello, hello, hello.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/2sec.wav')\n",
    "text = get_transcript(wave)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "/home/ali/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.25 s, sys: 521 ms, total: 6.78 s\n",
      "Wall time: 1.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Once upon a time, I mean was very thirsty.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/10sec.wav')\n",
    "text = get_transcript(wave)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 690 ms, total: 12.4 s\n",
      "Wall time: 3.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Okay, I am reading a name from the watch and my watch is of golden color and I am hearing a wind and a hand-free and a jacket and blue loch is and my say is asking me to test his model and I speak English in front of the laptop and that's all I guess.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/20sec.wav')\n",
    "text = get_transcript(wave)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "/home/ali/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.96 s, sys: 688 ms, total: 7.64 s\n",
      "Wall time: 1.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' We, the people of the United States, in order to form a more perfect union, establish'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/preamble_5sec_resample_with_pause.wav')\n",
    "text = get_transcript(wave)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 428 ms, total: 13.1 s\n",
      "Wall time: 3.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I arrived here just 5 minutes ago and now I am seeing a chair in front of me and two laptops and a person with glasses and white hairs and another person working on the laptop and I am all seeing a heater and two umbrellas and a fan and there are two glasses, two different other glasses and I am seeing here a lot of books and'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave = get_normalize_audio('audios/40sec.wav')\n",
    "text = get_transcript(wave)\n",
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times in Seconds\n",
    "\n",
    "| sec | Only Encoder | Encoder with Language Head |\n",
    "| 2s  | 1.52s        | 1.49\n",
    "| 8s  | 1.62s        | 1.64\n",
    "| 10s | 1.65         | 1.93\n",
    "| 20s | 1.97         | 2.5s\n",
    "| 40s | 1.66         | 3.28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9277e17e4d3b9136bb920fc4abbb2f884d2c051b4f6c35aa7accdfb2456c0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
